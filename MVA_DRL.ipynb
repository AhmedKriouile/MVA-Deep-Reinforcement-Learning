{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.7"
    },
    "colab": {
      "name": "MVA-DRL.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdMCPC2EMyl9",
        "colab_type": "text"
      },
      "source": [
        "**You may need to install [OpenCV](https://pypi.python.org/pypi/opencv-python) and [scikit-video](http://www.scikit-video.org/stable/).**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbZVfy2lMymD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "8ae322ec-694a-4a7f-d0af-54e457b579be"
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "import skvideo.io\n",
        "import cv2\n",
        "import json\n",
        "\n",
        "from keras.models import Sequential,model_from_json\n",
        "from keras.layers.core import Dense, Flatten\n",
        "from keras.optimizers import sgd\n",
        "from keras.layers import Conv2D, MaxPooling2D, Activation, AveragePooling2D,Reshape,BatchNormalization"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_2yWs8FMymN",
        "colab_type": "text"
      },
      "source": [
        "# MiniProject on Deep Reinforcement Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "777k2EGrMymR",
        "colab_type": "text"
      },
      "source": [
        "__Notations__: $E_p$ is the expectation under probability $p$. Please justify each of your answer and widely comment your code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaO4ue7LMymU",
        "colab_type": "text"
      },
      "source": [
        "# Context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDqtZmE9MymV",
        "colab_type": "text"
      },
      "source": [
        "In a reinforcement learning algorithm, we modelize each step $t$ as an action $a_t$ obtained from a state $s_t$, i.e. $\\{(a_{t},s_{t})_{t\\leq T}\\}$ having the Markov property. We consider a discount factor $\\gamma \\in [0,1]$ that ensures convergence. The goal is to find among all the policies $\\pi$, one that maximizes the expected reward:\n",
        "\n",
        "\\begin{equation*}\n",
        "R(\\pi)=\\sum_{t\\leq T}E_{p^{\\pi}}[\\gamma^t r(s_{t},a_{t})] \\> ,\n",
        "\\end{equation*}\n",
        "\n",
        "where: \n",
        "\\begin{equation*}p^{\\pi}(a_{0},a_{1},s_{1},...,a_{T},s_{T})=p(a_{0})\\prod_{t=1}^{T}\\pi(a_{t}|s_{t})p(s_{t+1}|s_{t},a_{t}) \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "We note the $Q$-function:\n",
        "\n",
        "\\begin{equation*}Q^\\pi(s,a)=E_{p^{\\pi}}[\\sum_{t\\leq T}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a] \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "Thus, the optimal Q function is:\n",
        "\\begin{equation*}\n",
        "Q^*(s,a)=\\max_{\\pi}Q^\\pi(s,a) \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "In this project, we will apply the deep reinforcement learning techniques to a simple game: an agent will have to learn from scratch a policy that will permit it maximizing a reward."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kguV5p6bMymX",
        "colab_type": "text"
      },
      "source": [
        "## The environment, the agent and the game"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlFajNt4MymZ",
        "colab_type": "text"
      },
      "source": [
        "### The environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dK973G1vMyma",
        "colab_type": "text"
      },
      "source": [
        "```Environment``` is an abstract class that represents the states, rewards, and actions to obtain the new state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwBWtK60Mymc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Environment(object):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def act(self, act):\n",
        "        \"\"\"\n",
        "        One can act on the environment and obtain its reaction:\n",
        "        - the new state\n",
        "        - the reward of the new state\n",
        "        - should we continue the game?\n",
        "\n",
        "        :return: state, reward, game_over\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "        Reinitialize the environment to a random state and returns\n",
        "        the original state\n",
        "\n",
        "        :return: state\n",
        "        \"\"\"\n",
        "        pass\n",
        "    \n",
        "    def draw(self):\n",
        "        \"\"\"\n",
        "        Visualize in the console or graphically the current state\n",
        "        \"\"\"\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTM5tpmiMymf",
        "colab_type": "text"
      },
      "source": [
        "The method ```act``` allows to act on the environment at a given state $s_t$ (stored internally), via action $a_t$. The method will return the new state $s_{t+1}$, the reward $r(s_{t},a_{t})$ and determines if $t\\leq T$ (*game_over*).\n",
        "\n",
        "The method ```reset``` simply reinitializes the environment to a random state $s_0$.\n",
        "\n",
        "The method ```draw``` displays the current state $s_t$ (this is useful to check the behavior of the Agent).\n",
        "\n",
        "We modelize $s_t$ as a tensor, while $a_t$ is an integer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIklof2JMymg",
        "colab_type": "text"
      },
      "source": [
        "### The Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNdP2wdfMymh",
        "colab_type": "text"
      },
      "source": [
        "The goal of the ```Agent``` is to interact with the ```Environment``` by proposing actions $a_t$ obtained from a given state $s_t$ to attempt to maximize its __reward__ $r(s_t,a_t)$. We propose the following abstract class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJ-NtjDwMymi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Agent(object):\n",
        "    def __init__(self, epsilon=0.1, n_action=4):\n",
        "        self.epsilon = epsilon\n",
        "        self.n_action = n_action\n",
        "    \n",
        "    def set_epsilon(self,e):\n",
        "        self.epsilon = e\n",
        "\n",
        "    def act(self,s,train=True):\n",
        "        \"\"\" This function should return the next action to do:\n",
        "        an integer between 0 and 4 (not included) with a random exploration of epsilon\"\"\"\n",
        "        if train:\n",
        "            if np.random.rand() <= self.epsilon:\n",
        "                a = np.random.randint(0, self.n_action, size=1)[0]\n",
        "            else:\n",
        "                a = self.learned_act(s)\n",
        "        else: # in some cases, this can improve the performance.. remove it if poor performances\n",
        "            a = self.learned_act(s)\n",
        "\n",
        "        return a\n",
        "\n",
        "    def learned_act(self,s):\n",
        "        \"\"\" Act via the policy of the agent, from a given state s\n",
        "        it proposes an action a\"\"\"\n",
        "        pass\n",
        "\n",
        "    def reinforce(self, s, n_s, a, r, game_over_):\n",
        "        \"\"\" This function is the core of the learning algorithm. \n",
        "        It takes as an input the current state s_, the next state n_s_\n",
        "        the action a_ used to move from s_ to n_s_ and the reward r_.\n",
        "        \n",
        "        Its goal is to learn a policy.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def save(self):\n",
        "        \"\"\" This function returns basic stats if applicable: the\n",
        "        loss and/or the model\"\"\"\n",
        "        pass\n",
        "\n",
        "    def load(self):\n",
        "        \"\"\" This function allows to restore a model\"\"\"\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chCQ-HzVMyml",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "__Question 1__:\n",
        "Explain the function act. Why is ```epsilon``` essential?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VM-09RQlMymm",
        "colab_type": "text"
      },
      "source": [
        "**act** is a function that returs the action that the **Agent** will take. **epsilon** is essential because it allows exploration of actions other that the exploitation one. Actually, with a probability of **1-epsilon**, the Agent take the action that he thinks maximize the reward (**exploration**), but with probability **epsilon**, the Agent take a random action which is essential to gain information about other policies that may lead to a better reward (**exploration**)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiQFVifhMymn",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "### The Game"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RP2HcXtrMymo",
        "colab_type": "text"
      },
      "source": [
        "The ```Agent``` and the ```Environment``` work in an interlaced way as in the following (take some time to understand this code as it is the core of the project)\n",
        "\n",
        "```python\n",
        "\n",
        "epoch = 300\n",
        "env = Environment()\n",
        "agent = Agent()\n",
        "\n",
        "\n",
        "# Number of won games\n",
        "score = 0\n",
        "loss = 0\n",
        "\n",
        "\n",
        "for e in range(epoch):\n",
        "    # At each epoch, we restart to a fresh game and get the initial state\n",
        "    state = env.reset()\n",
        "    # This assumes that the games will end\n",
        "    game_over = False\n",
        "\n",
        "    win = 0\n",
        "    lose = 0\n",
        "    \n",
        "    while not game_over:\n",
        "        # The agent performs an action\n",
        "        action = agent.act(state)\n",
        "\n",
        "        # Apply an action to the environment, get the next state, the reward\n",
        "        # and if the games end\n",
        "        prev_state = state\n",
        "        state, reward, game_over = env.act(action)\n",
        "\n",
        "        # Update the counters\n",
        "        if reward > 0:\n",
        "            win = win + reward\n",
        "        if reward < 0:\n",
        "            lose = lose -reward\n",
        "\n",
        "        # Apply the reinforcement strategy\n",
        "        loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "    # Save as a mp4\n",
        "    if e % 10 == 0:\n",
        "        env.draw(e)\n",
        "\n",
        "    # Update stats\n",
        "    score += win-lose\n",
        "\n",
        "    print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "          .format(e, epoch, loss, win, lose, win-lose))\n",
        "    agent.save()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4qifApAMymp",
        "colab_type": "text"
      },
      "source": [
        "# The game, *eat cheese*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4HFkNVFMymq",
        "colab_type": "text"
      },
      "source": [
        "A rat runs on an island and tries to eat as much as possible. The island is subdivided into $N\\times N$ cells, in which there are cheese (+0.5) and poisonous cells (-1). The rat has a visibility of 2 cells (thus it can see $5^2$ cells). The rat is given a time $T$ to accumulate as much food as possible. It can perform 4 actions: going up, down, left, right. \n",
        "\n",
        "The goal is to code an agent to solve this task that will learn by trial and error. We propose the following environment:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCJcqGOTMymr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Environment(object):\n",
        "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
        "        grid_size = grid_size+4\n",
        "        self.grid_size = grid_size\n",
        "        self.max_time = max_time\n",
        "        self.temperature = temperature\n",
        "\n",
        "        #board on which one plays\n",
        "        self.board = np.zeros((grid_size,grid_size))\n",
        "        self.position = np.zeros((grid_size,grid_size))\n",
        "\n",
        "        # coordinate of the cat\n",
        "        self.x = 0\n",
        "        self.y = 1\n",
        "\n",
        "        # self time\n",
        "        self.t = 0\n",
        "\n",
        "        self.scale=16\n",
        "\n",
        "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "    def draw(self,e):\n",
        "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
        "\n",
        "    def get_frame(self,t):\n",
        "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
        "        b[self.board>0,0] = 256\n",
        "        b[self.board < 0, 2] = 256\n",
        "        b[self.x,self.y,:]=256\n",
        "        b[-2:,:,:]=0\n",
        "        b[:,-2:,:]=0\n",
        "        b[:2,:,:]=0\n",
        "        b[:,:2,:]=0\n",
        "        \n",
        "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        self.to_draw[t,:,:,:]=b\n",
        "\n",
        "\n",
        "    def act(self, action):\n",
        "        \"\"\"This function returns the new state, reward and decides if the\n",
        "        game ends.\"\"\"\n",
        "\n",
        "        self.get_frame(int(self.t))\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "\n",
        "        self.position[self.x, self.y] = 1\n",
        "        if action == 0:\n",
        "            if self.x == self.grid_size-3:\n",
        "                self.x = self.x-1\n",
        "            else:\n",
        "                self.x = self.x + 1\n",
        "        elif action == 1:\n",
        "            if self.x == 2:\n",
        "                self.x = self.x+1\n",
        "            else:\n",
        "                self.x = self.x-1\n",
        "        elif action == 2:\n",
        "            if self.y == self.grid_size - 3:\n",
        "                self.y = self.y - 1\n",
        "            else:\n",
        "                self.y = self.y + 1\n",
        "        elif action == 3:\n",
        "            if self.y == 2:\n",
        "                self.y = self.y + 1\n",
        "            else:\n",
        "                self.y = self.y - 1\n",
        "        else:\n",
        "            RuntimeError('Error: action not recognized')\n",
        "\n",
        "        self.t = self.t + 1\n",
        "        reward = self.board[self.x, self.y]\n",
        "        self.board[self.x, self.y] = 0\n",
        "        game_over = self.t > self.max_time\n",
        "        state = np.concatenate((self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
        "\n",
        "        return state, reward, game_over\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
        "\n",
        "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "\n",
        "\n",
        "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
        "\n",
        "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
        "\n",
        "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "        malus[bonus>0]=0\n",
        "\n",
        "        self.board = bonus + malus\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.board[self.x,self.y] = 0\n",
        "        self.t = 0\n",
        "\n",
        "        state = np.concatenate((\n",
        "                               self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "\n",
        "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
        "        return state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DvvJO3GMymu",
        "colab_type": "text"
      },
      "source": [
        "The following elements are important because they correspond to the hyper parameters for this project:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7dTdUxCMymw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# parameters\n",
        "size = 13\n",
        "T=200\n",
        "temperature=0.3\n",
        "epochs_train=40 # set small when debugging\n",
        "epochs_test=40 # set small when debugging\n",
        "\n",
        "# display videos\n",
        "def display_videos(name):\n",
        "    video = io.open(name, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    return '''<video alt=\"test\" controls>\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hl0KVCeSMym4",
        "colab_type": "text"
      },
      "source": [
        "__Question 2__ Explain the use of the arrays ```position``` and ```board```."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-uulJtHMym6",
        "colab_type": "text"
      },
      "source": [
        "**position** is an array that represent and store the position of the **Agent**(the rat). Each case element of **position** represent a position in the grid or an impossible position.\n",
        "\n",
        "**board** is an array that stores the content and thus the reward of each position, +0,5 for cheese, -1 for poison and 0 if empty.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKeusoZUMym6",
        "colab_type": "text"
      },
      "source": [
        "## Random Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epfAEHbvMym7",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "__Question 3__ Implement a random Agent (only ```learned_act``` needs to be implemented):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYAwGTG5Mym8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RandomAgent(Agent):\n",
        "    def __init__(self):\n",
        "        super(RandomAgent, self).__init__()\n",
        "        pass\n",
        "\n",
        "    def learned_act(self, s):\n",
        "        return np.random.randint(0, self.n_action, size=1)[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVKXoxNSMym-",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__Question 4__ Visualize the game moves. You need to fill in the following function for the evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTAbHXTDMym_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(agent,env,epochs,prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "        \n",
        "    for e in range(epochs):\n",
        "        \n",
        "        # At each epoch, we restart to a fresh game and get the initial state\n",
        "        state = env.reset()\n",
        "        # This assumes that the games will end\n",
        "        game_over = False\n",
        "\n",
        "        win = 0\n",
        "        lose = 0\n",
        "\n",
        "        while not game_over:\n",
        "            # The agent performs an action\n",
        "            action = agent.act(state,train=False)\n",
        "\n",
        "            # Apply an action to the environment, get the next state, the reward\n",
        "            # and if the games end\n",
        "            prev_state = state\n",
        "            state, reward, game_over = env.act(action)\n",
        "\n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose -reward\n",
        "\n",
        "            # Apply the reinforcement strategy: here we do not do anything\n",
        "            #loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "        \n",
        "        # Save as a mp4\n",
        "        env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score = score + win-lose\n",
        "\n",
        "        print(\"Win/lose count {}/{}. Average score ({})\"\n",
        "              .format(win, lose, score/(1+e)))\n",
        "    print('Final score: '+str(score/epochs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofK5zaQQMynC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 657
        },
        "outputId": "2b38de5a-2912-4685-ce59-50500e5cf03a"
      },
      "source": [
        "# Initialize the game\n",
        "env = Environment(grid_size=size, max_time=T,temperature=temperature)\n",
        "\n",
        "# Initialize the agent!\n",
        "agent = RandomAgent()\n",
        "\n",
        "test(agent,env,epochs_test,prefix='random')\n",
        "HTML(display_videos('random0.mp4'))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Win/lose count 11.5/15.0. Average score (-3.5)\n",
            "Win/lose count 9.5/11.0. Average score (-2.5)\n",
            "Win/lose count 14.5/9.0. Average score (0.16666666666666666)\n",
            "Win/lose count 10.5/11.0. Average score (0.0)\n",
            "Win/lose count 11.5/12.0. Average score (-0.1)\n",
            "Win/lose count 12.0/15.0. Average score (-0.5833333333333334)\n",
            "Win/lose count 12.0/14.0. Average score (-0.7857142857142857)\n",
            "Win/lose count 8.5/16.0. Average score (-1.625)\n",
            "Win/lose count 9.0/12.0. Average score (-1.7777777777777777)\n",
            "Win/lose count 12.5/20.0. Average score (-2.35)\n",
            "Win/lose count 8.5/12.0. Average score (-2.4545454545454546)\n",
            "Win/lose count 12.0/15.0. Average score (-2.5)\n",
            "Win/lose count 11.0/18.0. Average score (-2.8461538461538463)\n",
            "Win/lose count 8.0/19.0. Average score (-3.4285714285714284)\n",
            "Win/lose count 7.5/13.0. Average score (-3.566666666666667)\n",
            "Win/lose count 14.5/23.0. Average score (-3.875)\n",
            "Win/lose count 9.5/11.0. Average score (-3.735294117647059)\n",
            "Win/lose count 7.0/10.0. Average score (-3.6944444444444446)\n",
            "Win/lose count 12.0/17.0. Average score (-3.763157894736842)\n",
            "Win/lose count 9.5/11.0. Average score (-3.65)\n",
            "Final score: -3.65\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTf1bgORMynF",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "## DQN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BiwDeMddMynG",
        "colab_type": "text"
      },
      "source": [
        "Let us assume here that $T=\\infty$.\n",
        "\n",
        "***\n",
        "__Question 5__ Let $\\pi$ be a policy, show that:\n",
        "\n",
        "\\begin{equation*}\n",
        "Q^{\\pi}(s,a)=E_{(s',a')\\sim p(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')]\n",
        "\\end{equation*}\n",
        "\n",
        "Then, show that for the optimal policy $\\pi^*$ (we assume its existence), the following holds: \n",
        "\n",
        "\\begin{equation*}\n",
        "Q^{*}(s,a)=E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)+\\gamma\\max_{a'}Q^{*}(s',a')].\n",
        "\\end{equation*}\n",
        "Finally, deduce that a plausible objective is:\n",
        "\n",
        "\\begin{equation*}\n",
        "\\mathcal{L}(\\theta)=E_{s' \\sim \\pi^*(.|s,a)}\\Vert r+\\gamma\\max\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}.\n",
        "\\end{equation*}\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoY3Pi3oMynG",
        "colab_type": "text"
      },
      "source": [
        "First:\n",
        "\\begin{aligned}\n",
        "Q^\\pi(s,a)&=E_{p^{\\pi}}[\\sum_{t\\leq \\infty}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a]\\\\\n",
        "&= E_{p^{\\pi}}[r(s_0,a_0) + \\sum_{1\\leq t\\leq \\infty}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a]\\\\\n",
        "&= E_{p^{\\pi}}[r(s_0,a_0)|s_{0}=s,a_{0}=a] + \\gamma E_{(s',a')\\sim p(.|s,a)}[E_{p^\\pi}[\\sum_{ t\\leq \\infty}\\gamma^{t}r(s_{t-1},a_{t-1})|s_0=s',a_0=a']]\\\\\n",
        "&=r(s,a)+\\gamma E_{(s',a')\\sim p(.|s,a)}[Q^{\\pi}(s',a')]\\\\\n",
        "&=E_{(s',a')\\sim p(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')]\\>\n",
        "\\end{aligned}\n",
        "\n",
        "Then:\n",
        "\\begin{aligned}\n",
        "Q^*(s,a)&=\\max_\\pi Q^\\pi(s,a)=\\max_\\pi \\left(r(s,a)+\\gamma E_{(s',a')\\sim p(.|s,a)}[Q^{\\pi}(s',a')]\\right)\\\\\n",
        "&=r(s,a)+\\gamma \\max_\\pi \\left( E_{(s',a')\\sim p(.|s,a)}[Q^{\\pi}(s',a')]\\right)=r(s,a)+\\gamma E_{s'\\sim \\pi^*(.|s,a)}[\\max_{a'} Q^*(s',a')]\n",
        "\\end{aligned}\n",
        "\n",
        "Finally:\n",
        "In order to verify the optimal Bellmann equation, the right term and the left term should close up until the difference converge to zero, a good loss is then the squared norm of the difference.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4U-fM6CbMynH",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "The DQN-learning algorithm relies on these derivations to train the parameters $\\theta$ of a Deep Neural Network:\n",
        "\n",
        "1. At the state $s_t$, select the action $a_t$ with best reward using $Q_t$ and store the results;\n",
        "\n",
        "2. Obtain the new state $s_{t+1}$ from the environment $p$;\n",
        "\n",
        "3. Store $(s_t,a_t,s_{t+1})$;\n",
        "\n",
        "4. Obtain $Q_{t+1}$ by minimizing  $\\mathcal{L}$ from a recovered batch from the previously stored results.\n",
        "\n",
        "***\n",
        "__Question 6__ Implement the class ```Memory``` that stores moves (in a replay buffer) via ```remember``` and provides a ```random_access``` to these. Specify a maximum memory size to avoid side effects. You can for example use a ```list()``` and set by default ```max_memory=100```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLxbAohZMynI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Memory(object):\n",
        "    def __init__(self, max_memory=100):\n",
        "        self.max_memory = max_memory\n",
        "        self.memory = list()\n",
        "\n",
        "    def remember(self, m):\n",
        "        if len(self.memory) >= self.max_memory:\n",
        "          del self.memory[0]\n",
        "        self.memory.append(m)\n",
        "\n",
        "    def random_access(self):\n",
        "        return self.memory[np.random.randint(0, len(self.memory),size=1)[0]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xB6CsjZMynK",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "The pipeline we will use for training is given below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNo5K2UMMynL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(agent,env,epoch,prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "    loss = 0\n",
        "\n",
        "    for e in range(epoch):\n",
        "        # At each epoch, we restart to a fresh game and get the initial state\n",
        "        state = env.reset()\n",
        "        # This assumes that the games will terminate\n",
        "        game_over = False\n",
        "\n",
        "        win = 0\n",
        "        lose = 0\n",
        "\n",
        "        while not game_over:\n",
        "            # The agent performs an action\n",
        "            action = agent.act(state)\n",
        "\n",
        "            # Apply an action to the environment, get the next state, the reward\n",
        "            # and if the games end\n",
        "            prev_state = state\n",
        "            state, reward, game_over = env.act(action)\n",
        "\n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose -reward\n",
        "\n",
        "            # Apply the reinforcement strategy\n",
        "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "        # Save as a mp4\n",
        "        if e % 10 == 0:\n",
        "            env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score += win-lose\n",
        "\n",
        "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "              .format(e, epoch, loss, win, lose, win-lose))\n",
        "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_fIAN3SMynN",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "__Question 7__ Implement the DQN training algorithm using a cascade of fully connected layers. You can use different learning rate, batch size or memory size parameters. In particular, the loss might oscillate while the player will start to win the games. You have to find a good criterium."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXGPJDdrMynO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DQN(Agent):\n",
        "    def __init__(self, grid_size,  epsilon = 0.1, memory_size=100, batch_size = 16,n_state=2):\n",
        "        super(DQN, self).__init__(epsilon = epsilon)\n",
        "\n",
        "        # Discount for Q learning\n",
        "        self.discount = 0.99\n",
        "        \n",
        "        self.grid_size = grid_size\n",
        "        \n",
        "        # number of state\n",
        "        self.n_state = n_state\n",
        "\n",
        "        # Memory\n",
        "        self.memory = Memory(memory_size)\n",
        "        \n",
        "        # Batch size when learning\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def learned_act(self, s):\n",
        "        return np.argmax(self.model.predict(s.reshape([1,s.shape[0],s.shape[1],s.shape[2]]))[0,:])\n",
        "\n",
        "    def reinforce(self, s_, n_s_, a_, r_, game_over_):\n",
        "        # Two steps: first memorize the states, second learn from the pool\n",
        "\n",
        "        self.memory.remember([s_, n_s_, a_, r_, game_over_])\n",
        "        \n",
        "        input_states = np.zeros((self.batch_size, 5,5,self.n_state))\n",
        "        target_q = np.zeros((self.batch_size, 4))\n",
        "        \n",
        "        for i in range(self.batch_size):\n",
        "            s_, n_s_, a_, r_, game_over_ = self.memory.random_access()\n",
        "            target_q[i] =self.model.predict(s_.reshape([1,s_.shape[0],s_.shape[1],s_.shape[2]]))[0]\n",
        "            if game_over_:\n",
        "                input_states[i] = s_\n",
        "                target_q[i,a_] = r_\n",
        "            else:\n",
        "                input_states[i] = s_\n",
        "                target_q[i,a_] = r_  + self.discount*max(self.model.predict(n_s_.reshape([1,s_.shape[0],s_.shape[1],s_.shape[2]]))[0])\n",
        "        target_q = np.clip(target_q, -3, 3)\n",
        "\n",
        "        l = self.model.train_on_batch(input_states, target_q)\n",
        "\n",
        "\n",
        "        return l\n",
        "\n",
        "    def save(self,name_weights='model.h5',name_model='model.json'):\n",
        "        self.model.save_weights(name_weights, overwrite=True)\n",
        "        with open(name_model, \"w\") as outfile:\n",
        "            json.dump(self.model.to_json(), outfile)\n",
        "            \n",
        "    def load(self,name_weights='model.h5',name_model='model.json'):\n",
        "        with open(name_model, \"r\") as jfile:\n",
        "            model = model_from_json(json.load(jfile))\n",
        "        model.load_weights(name_weights)\n",
        "        model.compile(\"sgd\", \"mse\")\n",
        "        self.model = model\n",
        "\n",
        "            \n",
        "class DQN_FC(DQN):\n",
        "    def __init__(self, *args, lr=0.1,**kwargs):\n",
        "        super(DQN_FC, self).__init__( *args,**kwargs)\n",
        "        \n",
        "        model = Sequential()\n",
        "        model.add(Flatten(input_shape=(5,5,self.n_state,)))\n",
        "        model.add(Dense(30,activation ='relu'))\n",
        "        model.add(Dense(4,activation = 'softmax'))\n",
        "        \n",
        "        model.compile(sgd(lr=lr, decay=1e-4, momentum=0.0), \"mse\")\n",
        "        self.model = model\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KN1BFCC4MynR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 987
        },
        "outputId": "f78a6b59-510c-427e-e5bc-5e586c2bbc40"
      },
      "source": [
        "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_FC(size, lr=.1, epsilon = 0.1, memory_size=500, batch_size = 32)\n",
        "train(agent, env, epochs_train, prefix='fc_train')\n",
        "HTML(display_videos('fc_train10.mp4'))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 000/040 | Loss 0.0003 | Win/lose count 1.5/1.0 (0.5)\n",
            "Epoch 001/040 | Loss 0.0017 | Win/lose count 4.5/3.0 (1.5)\n",
            "Epoch 002/040 | Loss 0.0064 | Win/lose count 3.5/6.0 (-2.5)\n",
            "Epoch 003/040 | Loss 0.0042 | Win/lose count 4.0/1.0 (3.0)\n",
            "Epoch 004/040 | Loss 0.0026 | Win/lose count 7.5/6.0 (1.5)\n",
            "Epoch 005/040 | Loss 0.0077 | Win/lose count 2.5/3.0 (-0.5)\n",
            "Epoch 006/040 | Loss 0.0037 | Win/lose count 3.5/2.0 (1.5)\n",
            "Epoch 007/040 | Loss 0.0064 | Win/lose count 7.0/3.0 (4.0)\n",
            "Epoch 008/040 | Loss 0.0105 | Win/lose count 3.0/4.0 (-1.0)\n",
            "Epoch 009/040 | Loss 0.0011 | Win/lose count 3.0/5.0 (-2.0)\n",
            "Epoch 010/040 | Loss 0.0216 | Win/lose count 2.0/5.0 (-3.0)\n",
            "Epoch 011/040 | Loss 0.0147 | Win/lose count 3.0/2.0 (1.0)\n",
            "Epoch 012/040 | Loss 0.0123 | Win/lose count 2.5/4.0 (-1.5)\n",
            "Epoch 013/040 | Loss 0.0095 | Win/lose count 6.0/5.0 (1.0)\n",
            "Epoch 014/040 | Loss 0.0028 | Win/lose count 5.0/4.0 (1.0)\n",
            "Epoch 015/040 | Loss 0.0034 | Win/lose count 4.0/3.0 (1.0)\n",
            "Epoch 016/040 | Loss 0.0137 | Win/lose count 3.5/3.0 (0.5)\n",
            "Epoch 017/040 | Loss 0.0036 | Win/lose count 6.0/5.0 (1.0)\n",
            "Epoch 018/040 | Loss 0.0090 | Win/lose count 2.5/0 (2.5)\n",
            "Epoch 019/040 | Loss 0.0101 | Win/lose count 3.0/0 (3.0)\n",
            "Epoch 020/040 | Loss 0.0084 | Win/lose count 10.0/5.0 (5.0)\n",
            "Epoch 021/040 | Loss 0.0125 | Win/lose count 4.5/4.0 (0.5)\n",
            "Epoch 022/040 | Loss 0.0080 | Win/lose count 5.0/7.0 (-2.0)\n",
            "Epoch 023/040 | Loss 0.0013 | Win/lose count 3.5/2.0 (1.5)\n",
            "Epoch 024/040 | Loss 0.0027 | Win/lose count 6.0/2.0 (4.0)\n",
            "Epoch 025/040 | Loss 0.0150 | Win/lose count 2.5/4.0 (-1.5)\n",
            "Epoch 026/040 | Loss 0.0091 | Win/lose count 6.5/5.0 (1.5)\n",
            "Epoch 027/040 | Loss 0.0021 | Win/lose count 8.5/1.0 (7.5)\n",
            "Epoch 028/040 | Loss 0.0109 | Win/lose count 2.5/5.0 (-2.5)\n",
            "Epoch 029/040 | Loss 0.0068 | Win/lose count 4.5/2.0 (2.5)\n",
            "Epoch 030/040 | Loss 0.0153 | Win/lose count 3.5/4.0 (-0.5)\n",
            "Epoch 031/040 | Loss 0.0057 | Win/lose count 2.0/3.0 (-1.0)\n",
            "Epoch 032/040 | Loss 0.0059 | Win/lose count 5.5/2.0 (3.5)\n",
            "Epoch 033/040 | Loss 0.0033 | Win/lose count 3.5/3.0 (0.5)\n",
            "Epoch 034/040 | Loss 0.0060 | Win/lose count 5.5/2.0 (3.5)\n",
            "Epoch 035/040 | Loss 0.0008 | Win/lose count 4.5/1.0 (3.5)\n",
            "Epoch 036/040 | Loss 0.0096 | Win/lose count 3.5/8.0 (-4.5)\n",
            "Epoch 037/040 | Loss 0.0153 | Win/lose count 5.0/3.0 (2.0)\n",
            "Epoch 038/040 | Loss 0.0152 | Win/lose count 1.5/1.0 (0.5)\n",
            "Epoch 039/040 | Loss 0.0055 | Win/lose count 4.0/4.0 (0.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6MbAif9MynT",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__Question 8__ Implement the DQN training algorithm using a CNN (for example, 2 convolutional layers and one final fully connected layer)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCTB-E86MynU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DQN_CNN(DQN):\n",
        "    def __init__(self, *args,lr=0.1,**kwargs):\n",
        "        super(DQN_CNN, self).__init__(*args,**kwargs)\n",
        "        \n",
        "        model = Sequential()\n",
        "        model.add(Conv2D(50,(2,2),input_shape=(5,5,self.n_state,),activation='relu'))\n",
        "        model.add(Conv2D(30,(2,2),activation='relu'))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4,activation='softmax'))\n",
        "\n",
        "        model.compile(sgd(lr=lr, decay=1e-4, momentum=0.0), \"mse\")\n",
        "        self.model = model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJNNH1KCMynW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 987
        },
        "outputId": "97a8bdbd-d8da-4702-f9d6-b86b7dfcf0cb"
      },
      "source": [
        "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=500, batch_size = 32)\n",
        "train(agent,env,epochs_train,prefix='cnn_train')\n",
        "HTML(display_videos('cnn_train10.mp4'))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 000/040 | Loss 0.0000 | Win/lose count 2.5/3.0 (-0.5)\n",
            "Epoch 001/040 | Loss 0.0000 | Win/lose count 0.5/2.0 (-1.5)\n",
            "Epoch 002/040 | Loss 0.0062 | Win/lose count 5.5/10.0 (-4.5)\n",
            "Epoch 003/040 | Loss 0.0100 | Win/lose count 10.0/12.0 (-2.0)\n",
            "Epoch 004/040 | Loss 0.0047 | Win/lose count 6.5/6.0 (0.5)\n",
            "Epoch 005/040 | Loss 0.0018 | Win/lose count 1.0/6.0 (-5.0)\n",
            "Epoch 006/040 | Loss 0.0000 | Win/lose count 2.5/3.0 (-0.5)\n",
            "Epoch 007/040 | Loss 0.0021 | Win/lose count 6.0/4.0 (2.0)\n",
            "Epoch 008/040 | Loss 0.0157 | Win/lose count 3.5/2.0 (1.5)\n",
            "Epoch 009/040 | Loss 0.0001 | Win/lose count 3.0/2.0 (1.0)\n",
            "Epoch 010/040 | Loss 0.0150 | Win/lose count 2.0/3.0 (-1.0)\n",
            "Epoch 011/040 | Loss 0.0022 | Win/lose count 6.0/6.0 (0.0)\n",
            "Epoch 012/040 | Loss 0.0025 | Win/lose count 2.0/2.0 (0.0)\n",
            "Epoch 013/040 | Loss 0.0020 | Win/lose count 1.5/3.0 (-1.5)\n",
            "Epoch 014/040 | Loss 0.0154 | Win/lose count 5.5/3.0 (2.5)\n",
            "Epoch 015/040 | Loss 0.0185 | Win/lose count 2.0/4.0 (-2.0)\n",
            "Epoch 016/040 | Loss 0.0039 | Win/lose count 5.5/2.0 (3.5)\n",
            "Epoch 017/040 | Loss 0.0024 | Win/lose count 2.5/3.0 (-0.5)\n",
            "Epoch 018/040 | Loss 0.0094 | Win/lose count 4.5/1.0 (3.5)\n",
            "Epoch 019/040 | Loss 0.0093 | Win/lose count 4.0/6.0 (-2.0)\n",
            "Epoch 020/040 | Loss 0.0001 | Win/lose count 0.5/1.0 (-0.5)\n",
            "Epoch 021/040 | Loss 0.0006 | Win/lose count 3.5/2.0 (1.5)\n",
            "Epoch 022/040 | Loss 0.0000 | Win/lose count 6.0/6.0 (0.0)\n",
            "Epoch 023/040 | Loss 0.0042 | Win/lose count 0.5/0 (0.5)\n",
            "Epoch 024/040 | Loss 0.0001 | Win/lose count 4.0/2.0 (2.0)\n",
            "Epoch 025/040 | Loss 0.0192 | Win/lose count 4.0/5.0 (-1.0)\n",
            "Epoch 026/040 | Loss 0.0022 | Win/lose count 3.0/2.0 (1.0)\n",
            "Epoch 027/040 | Loss 0.0001 | Win/lose count 2.5/3.0 (-0.5)\n",
            "Epoch 028/040 | Loss 0.0001 | Win/lose count 3.0/3.0 (0.0)\n",
            "Epoch 029/040 | Loss 0.0116 | Win/lose count 6.5/4.0 (2.5)\n",
            "Epoch 030/040 | Loss 0.0018 | Win/lose count 3.0/4.0 (-1.0)\n",
            "Epoch 031/040 | Loss 0.0001 | Win/lose count 4.5/2.0 (2.5)\n",
            "Epoch 032/040 | Loss 0.0063 | Win/lose count 3.0/1.0 (2.0)\n",
            "Epoch 033/040 | Loss 0.0001 | Win/lose count 5.5/5.0 (0.5)\n",
            "Epoch 034/040 | Loss 0.0039 | Win/lose count 4.5/2.0 (2.5)\n",
            "Epoch 035/040 | Loss 0.0074 | Win/lose count 3.5/2.0 (1.5)\n",
            "Epoch 036/040 | Loss 0.0022 | Win/lose count 1.5/1.0 (0.5)\n",
            "Epoch 037/040 | Loss 0.0001 | Win/lose count 3.5/4.0 (-0.5)\n",
            "Epoch 038/040 | Loss 0.0086 | Win/lose count 4.0/4.0 (0.0)\n",
            "Epoch 039/040 | Loss 0.0033 | Win/lose count 1.5/4.0 (-2.5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad4vB0juMynY",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__Question 9__ Test both algorithms and compare their performances. Which issue(s) do you observe? Observe also different behaviors by changing the temperature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qd56yW0MynY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bd252273-548b-4ebe-d696-c8054feba2c1"
      },
      "source": [
        "env = Environment(grid_size=size, max_time=T,temperature=0.3)\n",
        "agent_cnn = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "agent_cnn.load(name_weights='cnn_trainmodel.h5',name_model='cnn_trainmodel.json')\n",
        "\n",
        "agent_fc = DQN_FC(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "agent_cnn.load(name_weights='fc_trainmodel.h5',name_model='fc_trainmodel.json')\n",
        "print('Test of the CNN')\n",
        "test(agent_cnn,env,epochs_test,prefix='cnn_test')\n",
        "print('Test of the FC')\n",
        "test(agent_fc,env,epochs_test,prefix='fc_test')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test of the CNN\n",
            "Win/lose count 2.5/0. Average score (2.5)\n",
            "Win/lose count 2.0/0. Average score (2.25)\n",
            "Win/lose count 1.0/1.0. Average score (1.5)\n",
            "Win/lose count 3.0/0. Average score (1.875)\n",
            "Win/lose count 0.5/0. Average score (1.6)\n",
            "Win/lose count 0.5/0. Average score (1.4166666666666667)\n",
            "Win/lose count 2.0/0. Average score (1.5)\n",
            "Win/lose count 3.5/0. Average score (1.75)\n",
            "Win/lose count 1.0/0. Average score (1.6666666666666667)\n",
            "Win/lose count 1.5/0. Average score (1.5909090909090908)\n",
            "Win/lose count 4.0/0. Average score (1.7916666666666667)\n",
            "Win/lose count 0.5/0. Average score (1.6923076923076923)\n",
            "Win/lose count 2.5/0. Average score (1.75)\n",
            "Win/lose count 5.0/0. Average score (1.9666666666666666)\n",
            "Win/lose count 2.5/0. Average score (2.0)\n",
            "Win/lose count 1.5/0. Average score (1.9705882352941178)\n",
            "Win/lose count 0/1.0. Average score (1.8055555555555556)\n",
            "Win/lose count 4.0/1.0. Average score (1.868421052631579)\n",
            "Win/lose count 3.0/0. Average score (1.925)\n",
            "Win/lose count 2.5/0. Average score (1.9523809523809523)\n",
            "Win/lose count 3.5/2.0. Average score (1.9318181818181819)\n",
            "Win/lose count 5.5/0. Average score (2.0869565217391304)\n",
            "Win/lose count 4.0/0. Average score (2.1666666666666665)\n",
            "Win/lose count 0.5/1.0. Average score (2.06)\n",
            "Win/lose count 3.0/0. Average score (2.0961538461538463)\n",
            "Win/lose count 1.0/0. Average score (2.0555555555555554)\n",
            "Win/lose count 2.0/0. Average score (2.0535714285714284)\n",
            "Win/lose count 3.0/0. Average score (2.086206896551724)\n",
            "Win/lose count 2.0/0. Average score (2.0833333333333335)\n",
            "Win/lose count 3.5/1.0. Average score (2.096774193548387)\n",
            "Win/lose count 1.5/0. Average score (2.078125)\n",
            "Win/lose count 0.5/0. Average score (2.0303030303030303)\n",
            "Win/lose count 2.0/1.0. Average score (2.0)\n",
            "Win/lose count 2.0/1.0. Average score (1.9714285714285715)\n",
            "Win/lose count 3.5/0. Average score (2.013888888888889)\n",
            "Win/lose count 6.5/0. Average score (2.135135135135135)\n",
            "Win/lose count 3.0/1.0. Average score (2.1315789473684212)\n",
            "Win/lose count 1.0/0. Average score (2.1025641025641026)\n",
            "Win/lose count 1.0/1.0. Average score (2.05)\n",
            "Final score: 2.05\n",
            "Test of the FC\n",
            "Win/lose count 1.5/0. Average score (1.5)\n",
            "Win/lose count 0.5/0. Average score (1.0)\n",
            "Win/lose count 0/0. Average score (0.6666666666666666)\n",
            "Win/lose count 1.0/2.0. Average score (0.25)\n",
            "Win/lose count 1.5/1.0. Average score (0.3)\n",
            "Win/lose count 0/1.0. Average score (0.08333333333333333)\n",
            "Win/lose count 0.5/0. Average score (0.14285714285714285)\n",
            "Win/lose count 1.5/0. Average score (0.3125)\n",
            "Win/lose count 0/0. Average score (0.2777777777777778)\n",
            "Win/lose count 0.5/1.0. Average score (0.2)\n",
            "Win/lose count 0.5/0. Average score (0.22727272727272727)\n",
            "Win/lose count 0.5/1.0. Average score (0.16666666666666666)\n",
            "Win/lose count 0.5/0. Average score (0.19230769230769232)\n",
            "Win/lose count 0/0. Average score (0.17857142857142858)\n",
            "Win/lose count 0.5/1.0. Average score (0.13333333333333333)\n",
            "Win/lose count 0/3.0. Average score (-0.0625)\n",
            "Win/lose count 1.5/2.0. Average score (-0.08823529411764706)\n",
            "Win/lose count 2.5/0. Average score (0.05555555555555555)\n",
            "Win/lose count 0.5/0. Average score (0.07894736842105263)\n",
            "Win/lose count 1.0/0. Average score (0.125)\n",
            "Win/lose count 0/2.0. Average score (0.023809523809523808)\n",
            "Win/lose count 1.0/1.0. Average score (0.022727272727272728)\n",
            "Win/lose count 1.5/1.0. Average score (0.043478260869565216)\n",
            "Win/lose count 1.0/1.0. Average score (0.041666666666666664)\n",
            "Win/lose count 2.0/0. Average score (0.12)\n",
            "Win/lose count 0.5/2.0. Average score (0.057692307692307696)\n",
            "Win/lose count 0.5/1.0. Average score (0.037037037037037035)\n",
            "Win/lose count 1.0/0. Average score (0.07142857142857142)\n",
            "Win/lose count 0.5/1.0. Average score (0.05172413793103448)\n",
            "Win/lose count 1.5/1.0. Average score (0.06666666666666667)\n",
            "Win/lose count 0.5/1.0. Average score (0.04838709677419355)\n",
            "Win/lose count 0.5/0. Average score (0.0625)\n",
            "Win/lose count 0/1.0. Average score (0.030303030303030304)\n",
            "Win/lose count 0.5/0. Average score (0.04411764705882353)\n",
            "Win/lose count 1.5/0. Average score (0.08571428571428572)\n",
            "Win/lose count 0/0. Average score (0.08333333333333333)\n",
            "Win/lose count 0/0. Average score (0.08108108108108109)\n",
            "Win/lose count 1.0/3.0. Average score (0.02631578947368421)\n",
            "Win/lose count 0.5/0. Average score (0.038461538461538464)\n",
            "Win/lose count 1.5/1.0. Average score (0.05)\n",
            "Final score: 0.05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyqQrCkLMynb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "dc80ab61-ed55-460d-ddbb-6ba82eb03447"
      },
      "source": [
        "HTML(display_videos('cnn_test10.mp4'))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEZQuzYHMynd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "612258a8-31f8-4683-c746-ea004516dab5"
      },
      "source": [
        "HTML(display_videos('fc_test10.mp4'))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hFpsBpgMynf",
        "colab_type": "text"
      },
      "source": [
        "The poison is pretty well avoided by the rat with the two algorithms, but the cheese is not satisfiably eaten, the board is not well explored. The policies are too conservative. Relatively, the convolution network gives better rewards than fully connected network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWCA5z6YMyng",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "\n",
        "The algorithm tends to not explore the map which can be an issue. We propose two ideas in order to encourage exploration:\n",
        "1. Incorporating a decreasing $\\epsilon$-greedy exploration. You can use the method ```set_epsilon```\n",
        "2. Append via the environment a new state that describes if a cell has been visited or not\n",
        "\n",
        "***\n",
        "__Question 10__ Design a new ```train_explore``` function and environment class ```EnvironmentExploring``` to tackle the issue of exploration.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIpICJc6Myng",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_explore(agent,env,epoch,decay_parameter_epsilon=0.3,prefix=''):\n",
        "    \n",
        "    # Number of won games\n",
        "    score = 0\n",
        "    loss = 0\n",
        "\n",
        "    for e in range(epoch):\n",
        "        # At each epoch, we restart to a fresh game and get the initial state\n",
        "        state = env.reset()\n",
        "        # This assumes that the games will terminate\n",
        "        game_over = False\n",
        "\n",
        "        win = 0\n",
        "        lose = 0\n",
        "        agent.set_epsilon(agent.epsilon*(1-decay_parameter_epsilon))\n",
        "        while not game_over:\n",
        "            # The agent performs an action\n",
        "            action = agent.act(state)\n",
        "\n",
        "            # Apply an action to the environment, get the next state, the reward\n",
        "            # and if the games end\n",
        "            prev_state = state\n",
        "            state, reward, game_over = env.act(action, train=True)\n",
        "\n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose -reward\n",
        "\n",
        "            # Apply the reinforcement strategy\n",
        "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "        # Save as a mp4\n",
        "        if e % 10 == 0:\n",
        "            env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score += win-lose\n",
        "\n",
        "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "              .format(e, epoch, loss, win, lose, win-lose))\n",
        "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')\n",
        "        \n",
        "class EnvironmentExploring(object):\n",
        "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
        "        grid_size = grid_size+4\n",
        "        self.grid_size = grid_size\n",
        "        self.max_time = max_time\n",
        "        self.temperature = temperature\n",
        "\n",
        "        #board on which one plays\n",
        "        self.board = np.zeros((grid_size,grid_size))\n",
        "        self.position = np.zeros((grid_size,grid_size))\n",
        "        self.malus_position = np.zeros((grid_size,grid_size)) #define maluses when going to a previously visited position\n",
        "        # coordinate of the cat\n",
        "        self.x = 0\n",
        "        self.y = 1\n",
        "\n",
        "        # self time\n",
        "        self.t = 0\n",
        "\n",
        "        self.scale=16\n",
        "\n",
        "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "    def draw(self,e):\n",
        "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
        "\n",
        "    def get_frame(self,t):\n",
        "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
        "        b[self.board>0,0] = 256\n",
        "        b[self.board < 0, 2] = 256\n",
        "        b[self.x,self.y,:]=256\n",
        "        b[-2:,:,:]=0\n",
        "        b[:,-2:,:]=0\n",
        "        b[:2,:,:]=0\n",
        "        b[:,:2,:]=0\n",
        "        \n",
        "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        self.to_draw[t,:,:,:]=b\n",
        "\n",
        "\n",
        "    def act(self, action,train=False):\n",
        "        \"\"\"This function returns the new state, reward and decides if the\n",
        "        game ends.\"\"\"\n",
        "        #During the training phase going back to a position where the rat have already been before tends to decrease the \n",
        "        #total reward hence there is this train parameter that we have added (it tries to enforce the exploration)\n",
        "\n",
        "        self.get_frame(int(self.t))\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[:, -2:] = -1\n",
        "\n",
        "        self.position[self.x, self.y] = 1\n",
        "        if action == 0:\n",
        "            if self.x == self.grid_size-3:\n",
        "                self.x = self.x-1\n",
        "            else:\n",
        "                self.x = self.x + 1\n",
        "        elif action == 1:\n",
        "            if self.x == 2:\n",
        "                self.x = self.x+1\n",
        "            else:\n",
        "                self.x = self.x-1\n",
        "        elif action == 2:\n",
        "            if self.y == self.grid_size - 3:\n",
        "                self.y = self.y - 1\n",
        "            else:\n",
        "                self.y = self.y + 1\n",
        "        elif action == 3:\n",
        "            if self.y == 2:\n",
        "                self.y = self.y + 1\n",
        "            else:\n",
        "                self.y = self.y - 1\n",
        "        else:\n",
        "            RuntimeError('Error: action not recognized')\n",
        "\n",
        "        self.t = self.t + 1     \n",
        "        \n",
        "        ## In Environment exploring:\n",
        "        # You will have to change n_state to 3 because you will use one more layer!\n",
        "        reward = 0\n",
        "        if train:\n",
        "            reward = -self.malus_position[self.x, self.y]\n",
        "        self.malus_position[self.x, self.y] = 0.1\n",
        "\n",
        "        reward = reward + self.board[self.x, self.y]\n",
        "        self.board[self.x, self.y] = 0\n",
        "        game_over = self.t > self.max_time\n",
        "        # 3 \"feature\" states instead of 2\n",
        "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
        "                                        self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                                self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
        "\n",
        "        return state, reward, game_over\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
        "\n",
        "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "\n",
        "\n",
        "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
        "\n",
        "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
        "\n",
        "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "        malus[bonus>0]=0\n",
        "\n",
        "        self.board = bonus + malus\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[:,-2:] = -1\n",
        "        self.board[self.x,self.y] = 0\n",
        "        self.t = 0\n",
        "\n",
        "        self.malus_position = np.zeros((self.grid_size, self.grid_size))\n",
        "        #At the begining the malus_position array must be setted to zero\n",
        "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
        "                                        self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                                self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "\n",
        "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
        "        return state\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDN1_pchMynk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 987
        },
        "outputId": "4cc2e847-9730-4249-ebe7-378b62fe63a6"
      },
      "source": [
        "# Training\n",
        "env = EnvironmentExploring(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_CNN(size, lr=.1, epsilon = 1, memory_size=2000, batch_size = 32,n_state=3)\n",
        "train_explore(agent, env, epochs_train, prefix='cnn_train_explore')\n",
        "HTML(display_videos('cnn_train_explore10.mp4'))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 000/040 | Loss 0.0181 | Win/lose count 7.0/23.80000000000009 (-16.80000000000009)\n",
            "Epoch 001/040 | Loss 0.0021 | Win/lose count 6.5/21.000000000000025 (-14.500000000000025)\n",
            "Epoch 002/040 | Loss 0.0114 | Win/lose count 8.5/20.400000000000027 (-11.900000000000027)\n",
            "Epoch 003/040 | Loss 0.0058 | Win/lose count 5.5/23.00000000000007 (-17.50000000000007)\n",
            "Epoch 004/040 | Loss 0.0187 | Win/lose count 5.5/18.700000000000003 (-13.200000000000003)\n",
            "Epoch 005/040 | Loss 0.0090 | Win/lose count 2.5/20.200000000000024 (-17.700000000000024)\n",
            "Epoch 006/040 | Loss 0.0021 | Win/lose count 2.5/20.60000000000003 (-18.10000000000003)\n",
            "Epoch 007/040 | Loss 0.0037 | Win/lose count 8.0/20.100000000000023 (-12.100000000000023)\n",
            "Epoch 008/040 | Loss 0.0053 | Win/lose count 4.5/21.100000000000023 (-16.600000000000023)\n",
            "Epoch 009/040 | Loss 0.0185 | Win/lose count 3.5/20.40000000000001 (-16.90000000000001)\n",
            "Epoch 010/040 | Loss 0.0040 | Win/lose count 5.5/19.100000000000005 (-13.600000000000005)\n",
            "Epoch 011/040 | Loss 0.0171 | Win/lose count 5.5/18.599999999999998 (-13.099999999999998)\n",
            "Epoch 012/040 | Loss 0.0039 | Win/lose count 7.0/18.199999999999996 (-11.199999999999996)\n",
            "Epoch 013/040 | Loss 0.0038 | Win/lose count 2.0/19.200000000000003 (-17.200000000000003)\n",
            "Epoch 014/040 | Loss 0.0099 | Win/lose count 2.5/18.39999999999999 (-15.899999999999991)\n",
            "Epoch 015/040 | Loss 0.0079 | Win/lose count 2.5/18.699999999999996 (-16.199999999999996)\n",
            "Epoch 016/040 | Loss 0.0041 | Win/lose count 3.5/18.19999999999999 (-14.699999999999989)\n",
            "Epoch 017/040 | Loss 0.0025 | Win/lose count 14.5/16.399999999999967 (-1.8999999999999666)\n",
            "Epoch 018/040 | Loss 0.0030 | Win/lose count 6.0/17.199999999999974 (-11.199999999999974)\n",
            "Epoch 019/040 | Loss 0.0021 | Win/lose count 7.5/17.199999999999974 (-9.699999999999974)\n",
            "Epoch 020/040 | Loss 0.0131 | Win/lose count 4.5/18.7 (-14.2)\n",
            "Epoch 021/040 | Loss 0.0042 | Win/lose count 3.0/18.699999999999996 (-15.699999999999996)\n",
            "Epoch 022/040 | Loss 0.0075 | Win/lose count 6.0/17.399999999999977 (-11.399999999999977)\n",
            "Epoch 023/040 | Loss 0.0021 | Win/lose count 4.0/18.799999999999997 (-14.799999999999997)\n",
            "Epoch 024/040 | Loss 0.0148 | Win/lose count 0.5/19.500000000000007 (-19.000000000000007)\n",
            "Epoch 025/040 | Loss 0.0041 | Win/lose count 10.0/17.399999999999977 (-7.399999999999977)\n",
            "Epoch 026/040 | Loss 0.0036 | Win/lose count 11.0/20.60000000000003 (-9.60000000000003)\n",
            "Epoch 027/040 | Loss 0.0058 | Win/lose count 13.0/17.999999999999986 (-4.999999999999986)\n",
            "Epoch 028/040 | Loss 0.0136 | Win/lose count 3.5/18.699999999999996 (-15.199999999999996)\n",
            "Epoch 029/040 | Loss 0.0039 | Win/lose count 8.0/17.99999999999997 (-9.999999999999972)\n",
            "Epoch 030/040 | Loss 0.0039 | Win/lose count 1.5/19.0 (-17.5)\n",
            "Epoch 031/040 | Loss 0.0094 | Win/lose count 9.5/16.99999999999997 (-7.499999999999972)\n",
            "Epoch 032/040 | Loss 0.0040 | Win/lose count 5.0/17.999999999999986 (-12.999999999999986)\n",
            "Epoch 033/040 | Loss 0.0231 | Win/lose count 18.0/16.499999999999975 (1.5000000000000249)\n",
            "Epoch 034/040 | Loss 0.0130 | Win/lose count 1.0/19.60000000000001 (-18.60000000000001)\n",
            "Epoch 035/040 | Loss 0.0040 | Win/lose count 10.0/16.19999999999996 (-6.19999999999996)\n",
            "Epoch 036/040 | Loss 0.0039 | Win/lose count 7.0/17.69999999999998 (-10.699999999999982)\n",
            "Epoch 037/040 | Loss 0.0080 | Win/lose count 7.5/17.299999999999976 (-9.799999999999976)\n",
            "Epoch 038/040 | Loss 0.0058 | Win/lose count 1.0/19.200000000000003 (-18.200000000000003)\n",
            "Epoch 039/040 | Loss 0.0045 | Win/lose count 6.0/17.799999999999983 (-11.799999999999983)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SyNlmQlMynn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "353e9721-96a2-43b2-c9d5-f78059d86ca4"
      },
      "source": [
        "# Evaluation\n",
        "test(agent,env,epochs_test,prefix='cnn_test_explore')\n",
        "HTML(display_videos('cnn_test_explore10.mp4'))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Win/lose count 5.0/0. Average score (5.0)\n",
            "Win/lose count 5.0/0. Average score (5.0)\n",
            "Win/lose count 7.0/1.0. Average score (5.333333333333333)\n",
            "Win/lose count 4.5/1.0. Average score (4.875)\n",
            "Win/lose count 5.5/1.0. Average score (4.8)\n",
            "Win/lose count 3.0/0. Average score (4.5)\n",
            "Win/lose count 2.5/0. Average score (4.214285714285714)\n",
            "Win/lose count 2.0/1.0. Average score (3.8125)\n",
            "Win/lose count 2.0/0. Average score (3.611111111111111)\n",
            "Win/lose count 1.0/0. Average score (3.35)\n",
            "Win/lose count 3.5/1.0. Average score (3.272727272727273)\n",
            "Win/lose count 2.5/0. Average score (3.2083333333333335)\n",
            "Win/lose count 6.5/0. Average score (3.4615384615384617)\n",
            "Win/lose count 0/0. Average score (3.2142857142857144)\n",
            "Win/lose count 2.0/0. Average score (3.1333333333333333)\n",
            "Win/lose count 0.5/0. Average score (2.96875)\n",
            "Win/lose count 5.0/0. Average score (3.088235294117647)\n",
            "Win/lose count 0.5/0. Average score (2.9444444444444446)\n",
            "Win/lose count 1.5/0. Average score (2.8684210526315788)\n",
            "Win/lose count 6.5/0. Average score (3.05)\n",
            "Win/lose count 2.5/1.0. Average score (2.9761904761904763)\n",
            "Win/lose count 3.5/0. Average score (3.0)\n",
            "Win/lose count 6.0/2.0. Average score (3.0434782608695654)\n",
            "Win/lose count 4.0/0. Average score (3.0833333333333335)\n",
            "Win/lose count 3.5/0. Average score (3.1)\n",
            "Win/lose count 4.0/0. Average score (3.1346153846153846)\n",
            "Win/lose count 2.0/2.0. Average score (3.0185185185185186)\n",
            "Win/lose count 2.5/1.0. Average score (2.9642857142857144)\n",
            "Win/lose count 5.0/1.0. Average score (3.0)\n",
            "Win/lose count 4.5/0. Average score (3.05)\n",
            "Win/lose count 3.0/1.0. Average score (3.0161290322580645)\n",
            "Win/lose count 6.0/1.0. Average score (3.078125)\n",
            "Win/lose count 2.5/0. Average score (3.0606060606060606)\n",
            "Win/lose count 0.5/0. Average score (2.985294117647059)\n",
            "Win/lose count 1.0/1.0. Average score (2.9)\n",
            "Win/lose count 6.5/2.0. Average score (2.9444444444444446)\n",
            "Win/lose count 0.5/0. Average score (2.8783783783783785)\n",
            "Win/lose count 3.0/0. Average score (2.8815789473684212)\n",
            "Win/lose count 3.0/2.0. Average score (2.8333333333333335)\n",
            "Win/lose count 4.0/2.0. Average score (2.8125)\n",
            "Final score: 2.8125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dp5cbspkMyns",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__BONUS question__ Use the expert DQN from the previous question to generate some winning games. Train a model that mimicks its behavior. Compare the performances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6UI2015Myns",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGnXqHBAMynt",
        "colab_type": "text"
      },
      "source": [
        "***"
      ]
    }
  ]
}